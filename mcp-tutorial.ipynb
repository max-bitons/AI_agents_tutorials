{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an Agent with MCP: Seamless Integration of AI and External Resources\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Model Context Protocol (MCP) is an open protocol designed to standardize how applications provide context to large language models (LLMs). Think of MCP like a USB-C port for AI applications - just as USB-C provides a standardized way to connect devices to various peripherals, MCP provides a standardized way to connect AI models to different data sources and tools.\n",
    "\n",
    "This tutorial will guide you through implementing MCP in your AI agent applications, demonstrating how it can enhance your agents' capabilities by providing seamless access to external resources, tools, and data sources.\n",
    "\n",
    "## Why MCP Matters for Agents\n",
    "\n",
    "Traditional methods of connecting AI models with external resources often involve custom integrations for each data source or tool. This leads to:\n",
    "\n",
    "- **Integration Complexity**: Each new data source requires a unique implementation\n",
    "- **Scalability Issues**: Adding new tools becomes progressively harder\n",
    "- **Maintenance Overhead**: Updates to one integration may break others\n",
    "\n",
    "MCP solves these challenges by providing a standardized protocol that enables:\n",
    "\n",
    "- **Unified Access**: A single interface for multiple data sources and tools\n",
    "- **Plug-and-Play Extensions**: Easy addition of new capabilities\n",
    "- **Stateful Communication**: Real-time, two-way communication between AI and resources\n",
    "- **Dynamic Discovery**: AI can find and use new tools on the fly\n",
    "\n",
    "Here's a concise paragraph highlighting the official MCP Server examples:\n",
    "\n",
    "## Official MCP Server Examples\n",
    "\n",
    "The MCP community maintains a collection of reference server implementations that showcase best practices and demonstrate various integration patterns. These official examples, available at [MCP Servers](https://github.com/modelcontextprotocol/servers/tree/main/src), provide valuable starting points for developers looking to create their own MCP servers.\n",
    "\n",
    "## What We'll Build\n",
    "\n",
    "In this tutorial, we'll implement:\n",
    "\n",
    "1. **Build Your MCP Servers and Use It**: Build a MCP server with customized tools and connect to Claude Desktop\n",
    "2. **Customized Tool-Enabled Agent**: Create an customized agent that can use external tools via MCP\n",
    "\n",
    "By the end of this tutorial, you'll understand how MCP can enhance your AI agents by providing them with access to the broader digital ecosystem, making them more capable, context-aware, and useful.\n",
    "\n",
    "Let's begin by understanding the MCP architecture and setting up our environment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCP Architecture Overview\n",
    "\n",
    "![MCP Architecture](./images/mcp_architecture.png)\n",
    "\n",
    "MCP follows a client-server architecture with three main components:\n",
    "\n",
    "- **Host**: The AI application (like Claude Desktop, Cursor or a customized agent) that needs access to external resources\n",
    "- **Clients**: Connectors that maintain connections with servers\n",
    "- **Servers**: Lightweight programs that expose capabilities (data, tools, prompts) via the MCP protocol\n",
    "- **Data Sources**: Both local (files, databases) and remote services (APIs) that MCP servers can access\n",
    "\n",
    "Communication within MCP uses JSON-RPC 2.0 over WebSocket connections, ensuring real-time, bidirectional communication between components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiencing MCP: Try Before You Build\n",
    "\n",
    "While this tutorial focuses on building your own MCP servers and integrating them with AI agents, you might want to quickly experience how MCP works in practice before diving into development.\n",
    "\n",
    "The official MCP documentation provides an excellent quick start guide for users who want to try existing MCP servers with Claude Desktop or other compatible AI applications. This gives you a hands-on feel for the capabilities MCP enables without writing any code.\n",
    "\n",
    "**👉 Try it yourself:** [MCP Quick Start Guide for Users](https://modelcontextprotocol.io/quickstart/user)\n",
    "\n",
    "By exploring the quick start guide, you'll gain practical insight into what we're building in this tutorial. When you're ready to understand the inner workings and create your own implementations, continue with our step-by-step development process below.\n",
    "\n",
    "Now, let's start building our own MCP server and client!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Your MCP Server\n",
    "\n",
    "Now that we understand the basics of MCP, let's build our first MCP server! In this section, we'll create a cryptocurrency price lookup service using the CoinGecko API. Our server will provide tools that allow an AI to check the current price or market data of cryptocurrencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up Our Environment\n",
    "\n",
    "Before we dive into implementation, let's install the necessary packages and set up our environment.\n",
    "\n",
    "> **Note:** For the installation steps, please open a terminal window. These commands should be run in a regular terminal, not in a Jupyter notebook cell.\n",
    "\n",
    "#### Step 1: Install uv Package Manager\n",
    "\n",
    "```bash\n",
    "# Run this in your terminal, not in Jupyter\n",
    "curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "```\n",
    "\n",
    "#### Step 2: Set up the Project\n",
    "\n",
    "```bash\n",
    "# Create and navigate to a project directory\n",
    "mkdir mcp-crypto-server\n",
    "cd mcp-crypto-server\n",
    "uv init\n",
    "\n",
    "# Create and activate virtual environment\n",
    "uv venv\n",
    "source .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n",
    "\n",
    "# Install dependencies\n",
    "uv add \"mcp[cli]\" httpx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the MCP Server\n",
    "\n",
    "After we set up the envirnment, we can start build our tools.\n",
    "\n",
    "Please checkout [mcp_server.py](scripts/mcp_server.py) to see how to build tools.\n",
    "\n",
    "\n",
    "now we can start the server by runnning following commands in the ternimal:\n",
    "```bash\n",
    "# Copy the server file from the scripts folder\n",
    "cp ../scripts/mcp_server.py .\n",
    "\n",
    "# Start the MCP server \n",
    "uv run mcp_server.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration with Claude Desktop\n",
    "If you haven't download Claude Desktop, checkout [this page](https://claude.ai/download).\n",
    "\n",
    "To connect your MCP server to Claude Desktop:\n",
    "\n",
    "#### Step 1: Find the absolute path to your uv command:\n",
    "```bash\n",
    "which uv\n",
    "```\n",
    "Copy the output (e.g., /user/local/bin/uv or similar)\n",
    "\n",
    "#### Step 2: Create or edit the Claude Desktop configuration file:\n",
    "\n",
    "- On macOS: ~/Library/Application Support/Claude/claude_desktop_config.json\n",
    "- On Windows: %APPDATA%\\Claude\\claude_desktop_config.json\n",
    "- On Linux: ~/.config/Claude/claude_desktop_config.json\n",
    "\n",
    "You can checkout [this page](https://modelcontextprotocol.io/quickstart/user#2-add-the-filesystem-mcp-server) to see how to create a config file.\n",
    "\n",
    "#### Step 3: Add your MCP server configuration:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"mcpServers\": {\n",
    "        \"crypto-price-tracker\": {\n",
    "            \"command\": \"/ABSOLUTE/PATH/TO/uv\",\n",
    "            \"args\": [\n",
    "                \"--directory\",\n",
    "                \"/ABSOLUTE/PATH/TO/GenAI_Agents/all_agents_tutorials/mcp-crypto-server\",\n",
    "                \"run\",\n",
    "                \"mcp_server.py\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "Replace `/ABSOLUTE/PATH/TO/uv` with the path you got from the `which uv` command, and `/ABSOLUTE/PATH/TO/GenAI_Agents` with the absolute path to your repository.\n",
    "\n",
    "\n",
    "#### Step 4: Restart Claude Desktop for the changes to take effect.\n",
    "\n",
    "You should see this hammer in your chat box.\n",
    "\n",
    "![Claude Desktop connected with MCP](./images/Claude_Desktop_with_MCP.png)\n",
    "\n",
    "#### Step 5: Try ask the price of Bitcoin\n",
    "\n",
    "Type in \"What is the current price of Bitcoin ?\", and you will get response like:\n",
    "\n",
    "![Track Bitcoin price with MCP](./images/track_bitcoin_price_with_mcp.png)\n",
    "\n",
    "\n",
    "Congrats! You've successfully apply your MCP server and tool. Now, you can try add your own tools to [mcp_server.py](/mcp-crypto-server/mcp_server.py). Here is an example:\n",
    "\n",
    "```python\n",
    "@mcp.tool()\n",
    "async def get_crypto_market_info(crypto_ids: str, currency: str = \"usd\") -> str:\n",
    "    \"\"\"\n",
    "    Get market information for one or more cryptocurrencies.\n",
    "    \n",
    "    Parameters:\n",
    "    - crypto_ids: Comma-separated list of cryptocurrency IDs (e.g., 'bitcoin,ethereum')\n",
    "    - currency: The currency to display values in (default: 'usd')\n",
    "    \n",
    "    Returns:\n",
    "    - Market information including price, market cap, volume, and price changes\n",
    "    \"\"\"\n",
    "    # Construct the API URL\n",
    "    url = f\"{COINGECKO_BASE_URL}/coins/markets\"\n",
    "    \n",
    "    # Set up the query parameters\n",
    "    params = {\n",
    "        \"vs_currency\": currency,  # Currency to display values in\n",
    "        \"ids\": crypto_ids,        # Comma-separated crypto IDs\n",
    "        \"order\": \"market_cap_desc\", # Order by market cap\n",
    "        \"page\": 1,                # Page number\n",
    "        \"sparkline\": \"false\"      # Exclude sparkline data\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Make the API call\n",
    "        async with httpx.AsyncClient() as client:\n",
    "            response = await client.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            # Parse the response\n",
    "            data = response.json()\n",
    "            \n",
    "            # Check if we got any data\n",
    "            if not data:\n",
    "                return f\"No data found for cryptocurrencies: '{crypto_ids}'. Please check the IDs and try again.\"\n",
    "            \n",
    "            # Format the results\n",
    "            result = \"\"\n",
    "            for crypto in data:\n",
    "                name = crypto.get('name', 'Unknown')\n",
    "                symbol = crypto.get('symbol', '???').upper()\n",
    "                price = crypto.get('current_price', 'Unknown')\n",
    "                market_cap = crypto.get('market_cap', 'Unknown')\n",
    "                volume = crypto.get('total_volume', 'Unknown')\n",
    "                price_change = crypto.get('price_change_percentage_24h', 'Unknown')\n",
    "                \n",
    "                result += f\"{name} ({symbol}):\\n\"\n",
    "                result += f\"Current price: {price} {currency.upper()}\\n\"\n",
    "                result += f\"Market cap: {market_cap} {currency.upper()}\\n\"\n",
    "                result += f\"24h trading volume: {volume} {currency.upper()}\\n\"\n",
    "                result += f\"24h price change: {price_change}%\\n\\n\"\n",
    "            \n",
    "            return result\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error fetching market data: {str(e)}\"\n",
    "```\n",
    "\n",
    "Rerun your mcp server with `uv run mcp_server.py`, restart Claude Desktop, and type \"What's the market data for Dogecoin and Solana?\". You will get the response like this:\n",
    "\n",
    "![Track Crypto Market Data with MCP](./images/track_crypto_market_data_with_mcp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customized Agent executing tool via MCP\n",
    "\n",
    "After we build our own MCP, let's try building MCP Host & Client ourselves.\n",
    "\n",
    "### Understanding the Architecture\n",
    "\n",
    "In this section, we'll build our own MCP Host and Client. Unlike the previous approach where we connected to Claude Desktop, we'll now create our own agent that can:\n",
    "1. Act as an MCP Host\n",
    "2. Discover available tools from our MCP server\n",
    "3. Understand when to use which tool based on user queries\n",
    "4. Execute tools with appropriate parameters\n",
    "5. Process tool results to provide helpful responses\n",
    "\n",
    "This architecture follows a pattern common in modern AI systems:\n",
    "- **Discovery Phase**: Our custom host discovers what tools are available\n",
    "- **Planning Phase**: The agent decides which tool to use based on the user's query\n",
    "- **Execution Phase**: Our client connects to the server and executes the selected tool\n",
    "- **Interpretation Phase**: The agent explains the results in natural language\n",
    "\n",
    "Here is a simple worflow diagram:\n",
    "\n",
    "![Track Crypto Market Data with MCP](./images/customized_mcp_host.png)\n",
    "\n",
    "Important Reminder Before Running the Code:\n",
    "⚠️ Don't forget to start your MCP server first! ⚠️\n",
    "Before running the agent code in following tutorial, make sure your MCP server is up and running. Otherwise, your agent won't have any tools to discover or execute.\n",
    "\n",
    "Let's start by setting up our environment and importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install mcp anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need two primary libraries:\n",
    "- **MCP**: To handle the client-server communication with our MCP server, allowing us to build both the host and client components\n",
    "- **Anthropic**: To interact with Claude, which will power our agent's reasoning capabilities\n",
    "\n",
    "Now, let's set up the necessary imports and configurations for our agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# MCP libraries for connecting to server\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "# Anthropic API for Claude\n",
    "from anthropic import Anthropic\n",
    "\n",
    "# Set up Anthropic API key (using the one you provided)\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"your_anthropic_api_key_here\"\n",
    "\n",
    "# Initialize the Anthropic client\n",
    "client = Anthropic()\n",
    "\n",
    "# Path to your MCP server\n",
    "mcp_server_path = \"absolute/path/to/your/running/mcp/server\"\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using the `stdio_client` interface from MCP, which allows us to connect to MCP servers that run as separate processes and communicate via standard input/output. This is a simple and robust approach for local development. By implementing both sides of the MCP protocol (host and client), we gain complete control over how our agent interacts with MCP tools.\n",
    "\n",
    "### Tool Discovery: Building Our MCP Host\n",
    "\n",
    "The first step in building our custom MCP implementation is to create a host that can discover what tools are available from our MCP server. Our host will act as the intermediary between the user, the AI, and the available tools - similar to how Claude Desktop functions, but under our complete control.\n",
    "\n",
    "Let's implement a function to connect to our MCP server and discover its tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool discovery function defined\n"
     ]
    }
   ],
   "source": [
    "async def discover_tools():\n",
    "    \"\"\"\n",
    "    Connect to the MCP server and discover available tools.\n",
    "    Returns information about the available tools.\n",
    "    \"\"\"\n",
    "    # ANSI color codes for better log visibility\n",
    "    BLUE = \"\\033[94m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    SEP = \"=\" * 40\n",
    "    \n",
    "    # Create server parameters for connecting to your MCP server through stdio\n",
    "    server_params = StdioServerParameters(\n",
    "        command=\"python\",  # Command to run the server\n",
    "        args=[mcp_server_path],  # Path to your MCP server script\n",
    "    )\n",
    "    \n",
    "    print(f\"{BLUE}{SEP}\\n🔍 DISCOVERY PHASE: Connecting to MCP server...{RESET}\")\n",
    "    \n",
    "    # Connect to the server via stdio\n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        # Create a client session\n",
    "        async with ClientSession(read, write) as session:\n",
    "            # Initialize the connection\n",
    "            print(f\"{BLUE}📡 Initializing MCP connection...{RESET}\")\n",
    "            await session.initialize()\n",
    "            \n",
    "            # List the available tools\n",
    "            print(f\"{BLUE}🔎 Discovering available tools...{RESET}\")\n",
    "            tools = await session.list_tools()\n",
    "            \n",
    "            # Format the tools information for easier viewing\n",
    "            tool_info = []\n",
    "            for tool_type, tool_list in tools:\n",
    "                if tool_type == \"tools\":\n",
    "                    for tool in tool_list:\n",
    "                        tool_info.append({\n",
    "                            \"name\": tool.name,\n",
    "                            \"description\": tool.description,\n",
    "                            \"schema\": tool.inputSchema\n",
    "                        })\n",
    "            \n",
    "            print(f\"{GREEN}✅ Successfully discovered {len(tool_info)} tools{RESET}\")\n",
    "            print(f\"{SEP}\")\n",
    "            return tool_info\n",
    "\n",
    "print(\"Tool discovery function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function acts as our host's discovery component:\n",
    "\n",
    "1. **Creates Server Parameters**: Configures how to launch and connect to the MCP server\n",
    "2. **Establishes Connection**: Uses `stdio_client` to create a communication channel\n",
    "3. **Initializes Session**: Sets up the MCP session using the communication channel\n",
    "4. **Discovers Tools**: Calls `list_tools()` to get all available tools\n",
    "5. **Formats Results**: Converts the tools into a more usable format for our agent\n",
    "\n",
    "We're using an asynchronous approach (`async/await`) because MCP operations are non-blocking by design. This is important in a host implementation, as it allows our agent to handle multiple operations concurrently and remain responsive even when waiting for tool operations to complete.\n",
    "\n",
    "Let's test our tool discovery function to make sure it works properly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m========================================\n",
      "🔍 DISCOVERY PHASE: Connecting to MCP server...\u001b[0m\n",
      "\u001b[94m📡 Initializing MCP connection...\u001b[0m\n",
      "\u001b[94m🔎 Discovering available tools...\u001b[0m\n",
      "\u001b[92m✅ Successfully discovered 2 tools\u001b[0m\n",
      "========================================\n",
      "Discovered 2 tools:\n",
      "1. get_crypto_price: \n",
      "    Get the current price of a cryptocurrency in a specified currency.\n",
      "    \n",
      "    Parameters:\n",
      "    - crypto_id: The ID of the cryptocurrency (e.g., 'bitcoin', 'ethereum')\n",
      "    - currency: The currency to display the price in (default: 'usd')\n",
      "    \n",
      "    Returns:\n",
      "    - Current price information as a formatted string\n",
      "    \n",
      "2. get_crypto_market_info: \n",
      "    Get market information for one or more cryptocurrencies.\n",
      "    \n",
      "    Parameters:\n",
      "    - crypto_ids: Comma-separated list of cryptocurrency IDs (e.g., 'bitcoin,ethereum')\n",
      "    - currency: The currency to display values in (default: 'usd')\n",
      "    \n",
      "    Returns:\n",
      "    - Market information including price, market cap, volume, and price changes\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# Test the tool discovery function\n",
    "tools = await discover_tools()\n",
    "print(f\"Discovered {len(tools)} tools:\")\n",
    "for i, tool in enumerate(tools, 1):\n",
    "    print(f\"{i}. {tool['name']}: {tool['description']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run this code, we should see a list of the tools available from our MCP server. In this case, we're expecting to see our cryptocurrency tools.\n",
    "\n",
    "### Tool Execution: Implementing Our MCP Client\n",
    "\n",
    "Now that our host can discover available tools, we need to implement the client component that can execute them. Unlike third-party tools that might have this functionality built-in, we're creating our own client to execute MCP tools with complete control and transparency:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool execution function defined\n"
     ]
    }
   ],
   "source": [
    "async def execute_tool(tool_name: str, arguments: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Execute a specific tool provided by the MCP server.\n",
    "    \n",
    "    Args:\n",
    "        tool_name: The name of the tool to execute\n",
    "        arguments: A dictionary of arguments to pass to the tool\n",
    "        \n",
    "    Returns:\n",
    "        The result from executing the tool\n",
    "    \"\"\"\n",
    "    # ANSI color codes for better log visibility\n",
    "    BLUE = \"\\033[94m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    YELLOW = \"\\033[93m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    SEP = \"-\" * 40\n",
    "    \n",
    "    server_params = StdioServerParameters(\n",
    "        command=\"python\",\n",
    "        args=[mcp_server_path],\n",
    "    )\n",
    "    \n",
    "    print(f\"{YELLOW}{SEP}\")\n",
    "    print(f\"⚙️ EXECUTION PHASE: Running tool '{tool_name}'\")\n",
    "    print(f\"📋 Arguments: {json.dumps(arguments, indent=2)}\")\n",
    "    print(f\"{SEP}{RESET}\")\n",
    "    \n",
    "    async with stdio_client(server_params) as (read, write):\n",
    "        async with ClientSession(read, write) as session:\n",
    "            await session.initialize()\n",
    "            \n",
    "            # Call the specific tool with the provided arguments\n",
    "            print(f\"{BLUE}📡 Sending request to MCP server...{RESET}\")\n",
    "            result = await session.call_tool(tool_name, arguments)\n",
    "            \n",
    "            print(f\"{GREEN}✅ Tool execution complete{RESET}\")\n",
    "            \n",
    "            # Format result preview for cleaner output\n",
    "            result_preview = str(result)\n",
    "            if len(result_preview) > 150:\n",
    "                result_preview = result_preview[:147] + \"...\"\n",
    "                \n",
    "            print(f\"{BLUE}📊 Result: {result_preview}{RESET}\")\n",
    "            print(f\"{SEP}\")\n",
    "            \n",
    "            return result\n",
    "\n",
    "print(\"Tool execution function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function forms the core of our MCP client:\n",
    "\n",
    "1. **Connects to Server**: Similar to our discovery function, it establishes a connection to the MCP server\n",
    "2. **Executes Tool**: Calls the specified tool with the provided arguments\n",
    "3. **Returns Result**: Gives back whatever the tool returns\n",
    "\n",
    "Notice that for each tool execution, we create a new connection to the MCP server. While this may seem inefficient, it ensures clean separation between tool calls and avoids potential state issues. This stateless approach simplifies our implementation and makes it more robust. In a production system, you might optimize this by maintaining a persistent connection, but the current approach is excellent for educational purposes as it clearly separates each step in the process.\n",
    "\n",
    "Now that we have functions to discover and execute tools, we need to integrate these with an AI that can determine when and how to use them. This is where Claude comes in.\n",
    "\n",
    "### Integrating AI with Our MCP Implementation\n",
    "\n",
    "With our host and client components in place, we now need to integrate them with an AI system that can make intelligent decisions about tool usage. This is the \"brains\" of our custom MCP host, and it needs to:\n",
    "1. Understand when a tool is needed based on user input\n",
    "2. Choose the appropriate tool for the task\n",
    "3. Format the arguments correctly\n",
    "4. Process and explain the results\n",
    "\n",
    "Let's implement a function that orchestrates this entire process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude query function defined\n"
     ]
    }
   ],
   "source": [
    "async def query_claude(prompt: str, tool_info: List[Dict], previous_messages=None):\n",
    "    \"\"\"\n",
    "    Send a query to Claude and process the response.\n",
    "    \n",
    "    Args:\n",
    "        prompt: User's query\n",
    "        tool_info: Information about available tools\n",
    "        previous_messages: Previous messages for maintaining context\n",
    "        \n",
    "    Returns:\n",
    "        Claude's response, potentially after executing tools\n",
    "    \"\"\"\n",
    "    # ANSI color codes for better log visibility\n",
    "    BLUE = \"\\033[94m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    YELLOW = \"\\033[93m\"\n",
    "    PURPLE = \"\\033[95m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    SEP = \"=\" * 40\n",
    "    \n",
    "    if previous_messages is None:\n",
    "        previous_messages = []\n",
    "    \n",
    "    print(f\"{PURPLE}{SEP}\")\n",
    "    print(\"🧠 REASONING PHASE: Processing query with Claude\")\n",
    "    print(f\"🔤 Query: \\\"{prompt}\\\"\")\n",
    "    print(f\"{SEP}{RESET}\")\n",
    "    \n",
    "    # Format tool information for Claude\n",
    "    tool_descriptions = \"\\n\\n\".join([\n",
    "        f\"Tool: {tool['name']}\\nDescription: {tool['description']}\\nSchema: {json.dumps(tool['schema'], indent=2)}\"\n",
    "        for tool in tool_info\n",
    "    ])\n",
    "    \n",
    "    # Build the system prompt\n",
    "    system_prompt = f\"\"\"You are an AI assistant with access to specialized tools through MCP (Model Context Protocol).\n",
    "    \n",
    "Available tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "When you need to use a tool, respond with a JSON object in the following format:\n",
    "{{\n",
    "    \"tool\": \"tool_name\",\n",
    "    \"arguments\": {{\n",
    "        \"arg1\": \"value1\",\n",
    "        \"arg2\": \"value2\"\n",
    "    }}\n",
    "}}\n",
    "\n",
    "Do not include any other text when using a tool, just the JSON object.\n",
    "For regular responses, simply respond normally.\n",
    "\"\"\"\n",
    "    \n",
    "    # Filter out system messages from previous messages\n",
    "    filtered_messages = [msg for msg in previous_messages if msg[\"role\"] != \"system\"]\n",
    "    \n",
    "    # Build the messages for the conversation (WITHOUT system message)\n",
    "    messages = filtered_messages.copy()\n",
    "    \n",
    "    # Add the current user query\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    print(f\"{BLUE}📡 Sending request to Claude API...{RESET}\")\n",
    "    \n",
    "    # Send the request to Claude with system as a top-level parameter\n",
    "    response = client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=4000,\n",
    "        system=system_prompt,  # System prompt as a separate parameter\n",
    "        messages=messages      # Only user and assistant messages\n",
    "    )\n",
    "    \n",
    "    # Get Claude's response\n",
    "    claude_response = response.content[0].text\n",
    "    print(f\"{GREEN}✅ Received response from Claude{RESET}\")\n",
    "    \n",
    "    # Try to extract and parse JSON from the response\n",
    "    try:\n",
    "        # Look for JSON pattern in the response\n",
    "        import re\n",
    "        json_match = re.search(r'(\\{[\\s\\S]*\\})', claude_response)\n",
    "        \n",
    "        if json_match:\n",
    "            json_str = json_match.group(1)\n",
    "            print(f\"{YELLOW}🔍 Tool usage detected in response{RESET}\")\n",
    "            print(f\"{BLUE}📦 Extracted JSON: {json_str}{RESET}\")\n",
    "            \n",
    "            tool_request = json.loads(json_str)\n",
    "            \n",
    "            if \"tool\" in tool_request and \"arguments\" in tool_request:\n",
    "                tool_name = tool_request[\"tool\"]\n",
    "                arguments = tool_request[\"arguments\"]\n",
    "                \n",
    "                print(f\"{YELLOW}🔧 Claude wants to use tool: {tool_name}{RESET}\")\n",
    "                \n",
    "                # Execute the tool using our MCP client\n",
    "                tool_result = await execute_tool(tool_name, arguments)\n",
    "                \n",
    "                # Convert tool result to string if needed\n",
    "                if not isinstance(tool_result, str):\n",
    "                    tool_result = str(tool_result)\n",
    "                \n",
    "                # Update messages with the tool request and result\n",
    "                messages.append({\"role\": \"assistant\", \"content\": claude_response})\n",
    "                messages.append({\"role\": \"user\", \"content\": f\"Tool result: {tool_result}\"})\n",
    "                \n",
    "                print(f\"{PURPLE}🔄 Getting Claude's interpretation of the tool result...{RESET}\")\n",
    "                \n",
    "                # Get Claude's interpretation of the tool result\n",
    "                final_response = client.messages.create(\n",
    "                    model=\"claude-3-5-sonnet-20240620\",\n",
    "                    max_tokens=4000,\n",
    "                    system=system_prompt,\n",
    "                    messages=messages\n",
    "                )\n",
    "                \n",
    "                print(f\"{GREEN}✅ Final response ready{RESET}\")\n",
    "                print(f\"{SEP}\")\n",
    "                \n",
    "                return final_response.content[0].text, messages\n",
    "        \n",
    "    except (json.JSONDecodeError, KeyError, AttributeError) as e:\n",
    "        print(f\"{YELLOW}⚠️ No tool usage detected in response: {str(e)}{RESET}\")\n",
    "    \n",
    "    print(f\"{GREEN}✅ Response ready{RESET}\")\n",
    "    print(f\"{SEP}\")\n",
    "    \n",
    "    return claude_response, messages\n",
    "\n",
    "print(\"Claude query function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function completes our custom MCP host implementation with a sophisticated reasoning and execution flow:\n",
    "\n",
    "1. **Tool Description**: We format the tool information in a way Claude can understand\n",
    "2. **System Prompt**: We provide instructions on when and how to use tools\n",
    "3. **Response Analysis**: We look for JSON tool requests in Claude's responses\n",
    "4. **Tool Execution**: If a tool request is detected, we use our client to execute the appropriate tool\n",
    "5. **Result Processing**: We send the tool results back to Claude for interpretation\n",
    "6. **Conversation Management**: We maintain context by tracking messages\n",
    "\n",
    "This creates a powerful synergy: Claude provides the reasoning and communication skills, while our MCP tools provide specialized capabilities and real-time data access.\n",
    "\n",
    "Let's test our agent with a simple query about Bitcoin prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending query: What is the current price of Bitcoin?\n",
      "\u001b[95m========================================\n",
      "🧠 REASONING PHASE: Processing query with Claude\n",
      "🔤 Query: \"What is the current price of Bitcoin?\"\n",
      "========================================\u001b[0m\n",
      "\u001b[94m📡 Sending request to Claude API...\u001b[0m\n",
      "\u001b[92m✅ Received response from Claude\u001b[0m\n",
      "\u001b[93m🔍 Tool usage detected in response\u001b[0m\n",
      "\u001b[94m📦 Extracted JSON: {\n",
      "    \"tool\": \"get_crypto_price\",\n",
      "    \"arguments\": {\n",
      "        \"crypto_id\": \"bitcoin\"\n",
      "    }\n",
      "}\u001b[0m\n",
      "\u001b[93m🔧 Claude wants to use tool: get_crypto_price\u001b[0m\n",
      "\u001b[93m----------------------------------------\n",
      "⚙️ EXECUTION PHASE: Running tool 'get_crypto_price'\n",
      "📋 Arguments: {\n",
      "  \"crypto_id\": \"bitcoin\"\n",
      "}\n",
      "----------------------------------------\u001b[0m\n",
      "\u001b[94m📡 Sending request to MCP server...\u001b[0m\n",
      "\u001b[92m✅ Tool execution complete\u001b[0m\n",
      "\u001b[94m📊 Result: meta=None content=[TextContent(type='text', text='The current price of bitcoin is 83667 USD', annotations=None)] isError=False\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[95m🔄 Getting Claude's interpretation of the tool result...\u001b[0m\n",
      "\u001b[92m✅ Final response ready\u001b[0m\n",
      "========================================\n",
      "\n",
      "Assistant's response:\n",
      "Based on the tool result, I can provide you with the current price of Bitcoin:\n",
      "\n",
      "The current price of Bitcoin is $83,667 USD.\n",
      "\n",
      "This price is a real-time snapshot and can fluctuate rapidly due to the volatile nature of cryptocurrency markets. If you need more detailed information about Bitcoin's market performance, such as market cap, 24-hour volume, or price changes, I can use another tool to fetch that data for you. Would you like me to do that?\n"
     ]
    }
   ],
   "source": [
    "# Run a single query using the tools from your MCP server\n",
    "query = \"What is the current price of Bitcoin?\"\n",
    "print(f\"Sending query: {query}\")\n",
    "\n",
    "response, messages = await query_claude(query, tools)\n",
    "print(f\"\\nAssistant's response:\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run this query, our complete MCP implementation follows this flow:\n",
    "1. Claude (via our host) recognizes this as a request about Bitcoin prices\n",
    "2. Our AI decides to use the `get_crypto_price` tool\n",
    "3. It formats the arguments correctly (using \"bitcoin\" as the crypto_id)\n",
    "4. Our client connects to the server and executes the tool, returning the current Bitcoin price\n",
    "5. Claude explains the result in natural language with additional context\n",
    "\n",
    "This demonstrates the full capability of our agent: understanding the user's intent, selecting the appropriate tool, executing it correctly, and providing a helpful, context-rich response.\n",
    "\n",
    "### Direct Tool Execution via Our Client\n",
    "\n",
    "While our integrated MCP host typically decides which tools to use based on the user's query, sometimes we might want to directly use our client to execute a specific tool. This is useful for testing our client implementation or demonstrating specific tool functionality. Let's create a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing tool 'get_crypto_price' with arguments: {'crypto_id': 'bitcoin'}\n",
      "\u001b[93m----------------------------------------\n",
      "⚙️ EXECUTION PHASE: Running tool 'get_crypto_price'\n",
      "📋 Arguments: {\n",
      "  \"crypto_id\": \"bitcoin\"\n",
      "}\n",
      "----------------------------------------\u001b[0m\n",
      "\u001b[94m📡 Sending request to MCP server...\u001b[0m\n",
      "\u001b[92m✅ Tool execution complete\u001b[0m\n",
      "\u001b[94m📊 Result: meta=None content=[TextContent(type='text', text='The current price of bitcoin is 83670 USD', annotations=None)] isError=False\u001b[0m\n",
      "----------------------------------------\n",
      "Tool result: meta=None content=[TextContent(type='text', text='The current price of bitcoin is 83670 USD', annotations=None)] isError=False\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Get the first tool name from your discovered tools\n",
    "    if tools:\n",
    "        first_tool = tools[0]\n",
    "        tool_name = first_tool[\"name\"]\n",
    "        \n",
    "        # Use the correct parameter name for get_crypto_price\n",
    "        arguments = {\"crypto_id\": \"bitcoin\"}\n",
    "        \n",
    "        print(f\"Executing tool '{tool_name}' with arguments: {arguments}\")\n",
    "        result = await execute_tool(tool_name, arguments)\n",
    "        print(f\"Tool result: {result}\")\n",
    "    else:\n",
    "        print(\"No tools discovered to test\")\n",
    "except Exception as e:\n",
    "    print(f\"Error executing tool: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This direct execution approach is useful for:\n",
    "- Testing our client implementation in isolation\n",
    "- Debugging tool functionality\n",
    "- Building specialized workflows where tool execution is predetermined\n",
    "- Verifying that our MCP client works correctly before integrating it with the AI\n",
    "\n",
    "Now, let's create an interactive chat interface that uses our complete MCP host implementation:\n",
    "\n",
    "### Building an Interactive MCP Host Interface\n",
    "\n",
    "For a complete MCP host implementation, we need a user interface that maintains context across multiple turns of conversation. This allows our host to remember previous interactions and build on them in subsequent exchanges, just like professional MCP hosts such as Claude Desktop. Let's implement a simple chat session function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat session function defined. Run 'await chat_session()' in the next cell to start chatting.\n"
     ]
    }
   ],
   "source": [
    "async def chat_session():\n",
    "    \"\"\"\n",
    "    Run an interactive chat session with the AI agent.\n",
    "    \"\"\"\n",
    "    # ANSI color codes for better log visibility\n",
    "    BLUE = \"\\033[94m\"\n",
    "    GREEN = \"\\033[92m\"\n",
    "    YELLOW = \"\\033[93m\"\n",
    "    CYAN = \"\\033[96m\"\n",
    "    BOLD = \"\\033[1m\"\n",
    "    RESET = \"\\033[0m\"\n",
    "    SEP = \"=\" * 50\n",
    "    \n",
    "    print(f\"{CYAN}{BOLD}{SEP}\")\n",
    "    print(\"🤖 INITIALIZING MCP AGENT\")\n",
    "    print(f\"{SEP}{RESET}\")\n",
    "    \n",
    "    # Make sure 'tools' is defined from a previous cell, or discover them again\n",
    "    try:\n",
    "        # Check if tools is defined and not empty\n",
    "        if 'tools' not in globals() or not tools:\n",
    "            print(f\"{BLUE}🔍 No tools found, discovering available tools...{RESET}\")\n",
    "            tools_local = await discover_tools()\n",
    "        else:\n",
    "            tools_local = tools\n",
    "            \n",
    "        print(f\"{GREEN}✅ Agent ready with {len(tools_local)} tools:{RESET}\")\n",
    "        \n",
    "        # Print the available tools for reference\n",
    "        for i, tool in enumerate(tools_local, 1):\n",
    "            print(f\"{YELLOW}  {i}. {tool['name']}{RESET}\")\n",
    "            print(f\"     {tool['description'].strip()}\")\n",
    "        \n",
    "        # Start the chat session\n",
    "        print(f\"\\n{CYAN}{BOLD}{SEP}\")\n",
    "        print(f\"💬 INTERACTIVE CHAT SESSION\")\n",
    "        print(f\"{SEP}\")\n",
    "        print(f\"Type 'exit' or 'quit' to end the session{RESET}\")\n",
    "        \n",
    "        messages = []\n",
    "        \n",
    "        while True:\n",
    "            # Get user input\n",
    "            user_input = input(f\"\\n{BOLD}You:{RESET} \")\n",
    "            \n",
    "            # Check if user wants to exit\n",
    "            if user_input.lower() in ['exit', 'quit']:\n",
    "                print(f\"\\n{GREEN}Ending chat session. Goodbye!{RESET}\")\n",
    "                break\n",
    "            \n",
    "            # Process the query with Claude\n",
    "            print(f\"\\n{BLUE}Processing...{RESET}\")\n",
    "            response, messages = await query_claude(user_input, tools_local, messages)\n",
    "            \n",
    "            # Display Claude's response\n",
    "            print(f\"\\n{BOLD}Assistant:{RESET} {response}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n{YELLOW}⚠️ An error occurred: {str(e)}{RESET}\")\n",
    "\n",
    "print(\"Chat session function defined. Run 'await chat_session()' in the next cell to start chatting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our MCP host interface:\n",
    "\n",
    "1. **Initializes Tools**: Our host discovers available tools when starting\n",
    "2. **Creates a Session Loop**: Continuously prompts for user input\n",
    "3. **Maintains Context**: Passes previous messages to each query, maintaining stateful conversations\n",
    "4. **Handles Graceful Exit**: Allows the user to end the session gracefully\n",
    "\n",
    "This creates a natural, conversational experience where the agent can remember previous interactions. For example, if a user asks about Bitcoin and then follows up with \"How about Ethereum?\", the agent understands the context.\n",
    "\n",
    "Now, let's run our chat session to see the complete agent in action:\n",
    "\n",
    "You may try what we ask in Clude Desktop: What's the market data for Dogecoin and Solana?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[96m\u001b[1m==================================================\n",
      "🤖 INITIALIZING MCP AGENT\n",
      "==================================================\u001b[0m\n",
      "\u001b[92m✅ Agent ready with 2 tools:\u001b[0m\n",
      "\u001b[93m  1. get_crypto_price\u001b[0m\n",
      "     Get the current price of a cryptocurrency in a specified currency.\n",
      "    \n",
      "    Parameters:\n",
      "    - crypto_id: The ID of the cryptocurrency (e.g., 'bitcoin', 'ethereum')\n",
      "    - currency: The currency to display the price in (default: 'usd')\n",
      "    \n",
      "    Returns:\n",
      "    - Current price information as a formatted string\n",
      "\u001b[93m  2. get_crypto_market_info\u001b[0m\n",
      "     Get market information for one or more cryptocurrencies.\n",
      "    \n",
      "    Parameters:\n",
      "    - crypto_ids: Comma-separated list of cryptocurrency IDs (e.g., 'bitcoin,ethereum')\n",
      "    - currency: The currency to display values in (default: 'usd')\n",
      "    \n",
      "    Returns:\n",
      "    - Market information including price, market cap, volume, and price changes\n",
      "\n",
      "\u001b[96m\u001b[1m==================================================\n",
      "💬 INTERACTIVE CHAT SESSION\n",
      "==================================================\n",
      "Type 'exit' or 'quit' to end the session\u001b[0m\n",
      "\n",
      "\u001b[94mProcessing...\u001b[0m\n",
      "\u001b[95m========================================\n",
      "🧠 REASONING PHASE: Processing query with Claude\n",
      "🔤 Query: \"What's the market data for Dogecoin and Solana?\"\n",
      "========================================\u001b[0m\n",
      "\u001b[94m📡 Sending request to Claude API...\u001b[0m\n",
      "\u001b[92m✅ Received response from Claude\u001b[0m\n",
      "\u001b[93m🔍 Tool usage detected in response\u001b[0m\n",
      "\u001b[94m📦 Extracted JSON: {\n",
      "    \"tool\": \"get_crypto_market_info\",\n",
      "    \"arguments\": {\n",
      "        \"crypto_ids\": \"dogecoin,solana\"\n",
      "    }\n",
      "}\u001b[0m\n",
      "\u001b[93m🔧 Claude wants to use tool: get_crypto_market_info\u001b[0m\n",
      "\u001b[93m----------------------------------------\n",
      "⚙️ EXECUTION PHASE: Running tool 'get_crypto_market_info'\n",
      "📋 Arguments: {\n",
      "  \"crypto_ids\": \"dogecoin,solana\"\n",
      "}\n",
      "----------------------------------------\u001b[0m\n",
      "\u001b[94m📡 Sending request to MCP server...\u001b[0m\n",
      "\u001b[92m✅ Tool execution complete\u001b[0m\n",
      "\u001b[94m📊 Result: meta=None content=[TextContent(type='text', text='Solana (SOL):\\nCurrent price: 120.93 USD\\nMarket cap: 62246986425 USD\\n24h trading volume: 566579...\u001b[0m\n",
      "----------------------------------------\n",
      "\u001b[95m🔄 Getting Claude's interpretation of the tool result...\u001b[0m\n",
      "\u001b[92m✅ Final response ready\u001b[0m\n",
      "========================================\n",
      "\n",
      "\u001b[1mAssistant:\u001b[0m Thank you for providing the market data. I'll summarize the information for Dogecoin and Solana:\n",
      "\n",
      "Solana (SOL):\n",
      "1. Current price: $120.93\n",
      "2. Market cap: $62,246,986,425\n",
      "3. 24h trading volume: $5,665,790,205\n",
      "4. 24h price change: +5.01%\n",
      "\n",
      "Dogecoin (DOGE):\n",
      "1. Current price: $0.169366\n",
      "2. Market cap: $25,197,463,810\n",
      "3. 24h trading volume: $1,635,314,095\n",
      "4. 24h price change: +4.39%\n",
      "\n",
      "Both cryptocurrencies have shown positive price movements in the last 24 hours, with Solana experiencing a slightly higher increase compared to Dogecoin. Solana has a significantly higher market capitalization and trading volume than Dogecoin. \n",
      "\n",
      "Is there any specific aspect of this market data you'd like me to elaborate on or any other information you need about these cryptocurrencies?\n",
      "\n",
      "\u001b[92mEnding chat session. Goodbye!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the chat session\n",
    "await chat_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this final piece, we've created a complete custom MCP host implementation that can:\n",
    "1. Connect to an MCP server as a client\n",
    "2. Discover available tools\n",
    "3. Intelligently select and use those tools to answer user queries\n",
    "4. Maintain context across a conversation\n",
    "\n",
    "This demonstrates the power of implementing our own MCP host and client - we get complete control over how AI interacts with tools while maintaining all the benefits of the MCP protocol's standardization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The Model Context Protocol represents a transformative approach to integrating AI models with external resources, solving critical challenges in AI application development:\n",
    "\n",
    "### Protocol Advantages\n",
    "- **Standardized Integration**: Eliminates complex, custom API connections\n",
    "- **Dynamic Tool Discovery**: Enables AI to find and use tools seamlessly\n",
    "- **Flexible Communication**: Supports real-time, bidirectional interactions\n",
    "\n",
    "### Technical Highlights\n",
    "Our implementation demonstrated:\n",
    "- Building MCP server with specialized tools\n",
    "- Creating a host that can dynamically discover and execute tools\n",
    "- Integrating AI model with external resources\n",
    "\n",
    "### Key Citations\n",
    "\n",
    "- [Python MCP SDK](https://github.com/modelcontextprotocol/python-sdk)\n",
    "- [MCP Quick Start Guide](https://modelcontextprotocol.io/quickstart/user)\n",
    "- [CoinGecko API Documentation](https://www.coingecko.com/en/api)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
